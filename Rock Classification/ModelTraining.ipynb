{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"R6Grut_r4etP"},"outputs":[],"source":["# This script trains the respective models using the data prepared from DataPreparation.ipynb.\n","# There are 2 parts to this\n","#\n","# A) We train & evaluate using Classification Models with Target['T']\n","#    to predict the age of volcanic rocks.\n","#    Models to be tested are: Logistic Regression (Baseline); Random Forest and 1 Neural Network\n","#    Metrics used are (accuracy_score, F1_score). Precision and Recall - are produced in the Classification Report\n","#    Our performance metric for (A) is F1-score coz its gives a balance between precision and recall.\n","#\n","# B) We will extend the training and evaluation further by using Linear Regression with Target['Mg#']\n","#    to predict which dataset elements(EMPA or Laser)  have a stronger influence on Mg#\n","#    WHy Mg#? - Mg# is mathematically derived from other elements and it has some influence on Age of rocks.\n","#    Metrics used are (r2_score and mean_squared_error).  Metric focus will be r2_score."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","import pandas as pd\n","import warnings\n","import os\n","\n","from pathlib import Path\n","\n","from sklearn.linear_model import LogisticRegression, LinearRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import (\n","    accuracy_score,\n","    f1_score,\n","    classification_report,\n","    confusion_matrix,\n","    mean_squared_error,\n","    r2_score\n",")\n","\n","# setting deterministic behaviour for ANN training\n","# to get consistency and reduce run-to-run variability on the Neural Network results\n","os.environ['PYTHONHASHSEED'] = '42'\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'   # best-effort deterministic ops\n","import random\n","random.seed(42)\n","np.random.seed(42)\n","\n","# Deep Learning\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Input\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","\n","#\n","# Set random seed to 42\n","# so we get the same result everytime this code runs\n","#\n","tf.random.set_seed(42)"],"metadata":{"id":"citDDD6V7_Ix","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f2ab146c-edad-4fc3-e219-65632c149dc2","executionInfo":{"status":"ok","timestamp":1766760009165,"user_tz":0,"elapsed":30879,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Paths (Making directory)\n","ROOT = Path(\"/content/drive/MyDrive/Intro2Prog\")\n","DATA_PREP = ROOT / \"Data_Prepared\"\n","RESULTS   = ROOT / \"Results\"\n","LR_DIR = RESULTS / \"Logistic_Regression\"\n","RF_DIR = RESULTS / \"Random_Forest\"\n","NN_DIR = RESULTS / \"Neural_Network\"\n","\n","REG_DIR = RESULTS / \"Linear_Regression\"\n","\n","RESULTS.mkdir(parents=True, exist_ok=True)\n","LR_DIR.mkdir(parents=True, exist_ok=True)\n","RF_DIR.mkdir(parents=True, exist_ok=True)\n","NN_DIR.mkdir(parents=True, exist_ok=True)\n","\n","REG_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Initiatizing results var to capture the performance metrics for (A - Classification)\n","results = []\n","# Initializing reg_results var to capture performance metrics for (B - Regression)\n","reg_results = []\n"],"metadata":{"id":"0Kx-0LM38FMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading Prepared Data for (A - Classification)\n","#\n","# Empa Dataset\n","X_empa_train = np.load(DATA_PREP / \"X_empa_train.npy\")\n","X_empa_test  = np.load(DATA_PREP / \"X_empa_test.npy\")\n","y_empa_train = np.load(DATA_PREP / \"y_empa_train.npy\")\n","y_empa_test  = np.load(DATA_PREP / \"y_empa_test.npy\")\n","\n","# Laser Dataset\n","X_laser_train = np.load(DATA_PREP / \"X_laser_train.npy\")\n","X_laser_test  = np.load(DATA_PREP / \"X_laser_test.npy\")\n","y_laser_train = np.load(DATA_PREP / \"y_laser_train.npy\")\n","y_laser_test  = np.load(DATA_PREP / \"y_laser_test.npy\")\n","\n","# Combined\n","X_comb_train = np.load(DATA_PREP / \"X_comb_train.npy\")\n","X_comb_test  = np.load(DATA_PREP / \"X_comb_test.npy\")\n","y_comb_train = np.load(DATA_PREP / \"y_comb_train.npy\")\n","y_comb_test  = np.load(DATA_PREP / \"y_comb_test.npy\")\n","\n","# Loading Prepared Data for (B - Regression)\n","# EMPA - FULL\n","X_empa_reg_train = np.load(DATA_PREP / \"X_empa_reg_train.npy\")\n","X_empa_reg_test  = np.load(DATA_PREP / \"X_empa_reg_test.npy\")\n","y_empa_reg_train = np.load(DATA_PREP / \"y_empa_reg_train.npy\")\n","y_empa_reg_test  = np.load(DATA_PREP / \"y_empa_reg_test.npy\")\n","\n","# LASER\n","X_laser_reg_train = np.load(DATA_PREP / \"X_laser_reg_train.npy\")\n","X_laser_reg_test  = np.load(DATA_PREP / \"X_laser_reg_test.npy\")\n","y_laser_reg_train = np.load(DATA_PREP / \"y_laser_reg_train.npy\")\n","y_laser_reg_test  = np.load(DATA_PREP / \"y_laser_reg_test.npy\")\n","\n","# COMBINED\n","X_comb_reg_train = np.load(DATA_PREP / \"X_comb_reg_train.npy\")\n","X_comb_reg_test  = np.load(DATA_PREP / \"X_comb_reg_test.npy\")\n","y_comb_reg_train = np.load(DATA_PREP / \"y_comb_reg_train.npy\")\n","y_comb_reg_test  = np.load(DATA_PREP / \"y_comb_reg_test.npy\")\n"],"metadata":{"id":"rEKYXogtAf_m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###################################################################################################################\n","#\n","# Part A - Predicting the Age of Volcanic Rocks setting column['T] as Target and using ML and Deep Learning Models\n","# - Training with Logistic Regession for EMPA(653 rows), Laser(189 rows) and Combined(EMPA Reduced(189) + Laser (189)\n","#\n","###################################################################################################################"],"metadata":{"id":"yj6-0AC5o3sO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["####################################\n","# Training with Logistic Regression\n","###################################\n","\n","# 1. EMPA Dataset\n","#\n","lr_empa = LogisticRegression(max_iter=1000) #sets the maximum number of steps the model can take to learn\n","lr_empa.fit(X_empa_train, y_empa_train)\n","\n","y_pred = lr_empa.predict(X_empa_test)\n","\n","acc = accuracy_score(y_empa_test, y_pred)\n","f1  = f1_score(y_empa_test, y_pred, average=\"weighted\") #For multiple classes\n","\n","report = classification_report(y_empa_test, y_pred)\n","\n","print(\"\\nLogistic Regression — EMPA\")\n","print(report)\n","\n","#Opens up classification file to write to it\n","with open(LR_DIR / \"EMPA_classification_report.txt\", \"w\") as f:\n","    f.write(report)\n","\n","results.append([\"EMPA\", \"Logistic Regression\", acc, f1])\n"],"metadata":{"id":"gQItTA3cMHGL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b93c062b-7c58-49ca-f97a-9da759a034ff","executionInfo":{"status":"ok","timestamp":1766760017667,"user_tz":0,"elapsed":71,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Logistic Regression — EMPA\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.60      0.60        53\n","           1       0.73      0.85      0.79        52\n","           2       0.53      0.35      0.42        26\n","\n","    accuracy                           0.65       131\n","   macro avg       0.62      0.60      0.60       131\n","weighted avg       0.64      0.65      0.64       131\n","\n"]}]},{"cell_type":"code","source":["#\n","# 2. Laser Dataset\n","#\n","lr_laser = LogisticRegression(max_iter=1000)\n","lr_laser.fit(X_laser_train, y_laser_train)\n","\n","y_pred = lr_laser.predict(X_laser_test)\n","\n","acc = accuracy_score(y_laser_test, y_pred)\n","f1  = f1_score(y_laser_test, y_pred, average=\"weighted\")\n","\n","report = classification_report(y_laser_test, y_pred)\n","\n","print(\"\\nLogistic Regression — Laser\")\n","print(report)\n","\n","with open(LR_DIR / \"Laser_classification_report.txt\", \"w\") as f:\n","    f.write(report)\n","\n","results.append([\"Laser\", \"Logistic Regression\", acc, f1])"],"metadata":{"id":"l-hQi6RDBg2m","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf2aa30a-7f7e-4bc1-ec2b-f48e32ace196","executionInfo":{"status":"ok","timestamp":1766760017792,"user_tz":0,"elapsed":120,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Logistic Regression — Laser\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.81      0.84        16\n","           1       0.75      0.90      0.82        10\n","           2       1.00      0.92      0.96        12\n","\n","    accuracy                           0.87        38\n","   macro avg       0.87      0.88      0.87        38\n","weighted avg       0.88      0.87      0.87        38\n","\n"]}]},{"cell_type":"code","source":["#\n","# 3. Combined Dataset\n","#\n","lr_comb = LogisticRegression(max_iter=1000)\n","lr_comb.fit(X_comb_train, y_comb_train)\n","\n","y_pred = lr_comb.predict(X_comb_test)\n","\n","acc = accuracy_score(y_comb_test, y_pred)\n","f1  = f1_score(y_comb_test, y_pred, average=\"weighted\")\n","\n","report = classification_report(y_comb_test, y_pred)\n","\n","print(\"\\nLogistic Regression — Combined\")\n","print(report)\n","\n","with open(LR_DIR / \"Combined_classification_report.txt\", \"w\") as f:\n","    f.write(report)\n","\n","results.append([\"Combined\", \"Logistic Regression\", acc, f1])"],"metadata":{"id":"bs7ylbAABozz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9edab137-0d56-4cc0-b4a2-3200c497d7e2","executionInfo":{"status":"ok","timestamp":1766760017796,"user_tz":0,"elapsed":3,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Logistic Regression — Combined\n","              precision    recall  f1-score   support\n","\n","           0       0.94      1.00      0.97        16\n","           1       1.00      1.00      1.00        10\n","           2       1.00      0.92      0.96        12\n","\n","    accuracy                           0.97        38\n","   macro avg       0.98      0.97      0.98        38\n","weighted avg       0.98      0.97      0.97        38\n","\n"]}]},{"cell_type":"code","source":["##################################################\n","# Training with Random Forest\n","##################################################\n","\n","# 1. Empa Dataset\n","#\n","rf_empa = RandomForestClassifier(n_estimators=200, random_state=42) #200decision trees, reproducible results\n","rf_empa.fit(X_empa_train, y_empa_train)\n","\n","y_pred = rf_empa.predict(X_empa_test)\n","\n","acc = accuracy_score(y_empa_test, y_pred)\n","f1  = f1_score(y_empa_test, y_pred, average=\"weighted\") #For multiple classes\n","\n","report = classification_report(y_empa_test, y_pred)\n","\n","print(\"\\nRandom Forest — EMPA\")\n","print(report)\n","\n","with open(RF_DIR / \"EMPA_classification_report.txt\", \"w\") as f:\n","    f.write(report)\n","\n","results.append([\"EMPA\", \"Random Forest\", acc, f1])"],"metadata":{"id":"Fhl1XftbB1va","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f096ee43-da49-4de0-a851-260aa7c5008e","executionInfo":{"status":"ok","timestamp":1766760018539,"user_tz":0,"elapsed":741,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Random Forest — EMPA\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.77      0.77        53\n","           1       0.74      0.87      0.80        52\n","           2       0.82      0.54      0.65        26\n","\n","    accuracy                           0.76       131\n","   macro avg       0.78      0.73      0.74       131\n","weighted avg       0.77      0.76      0.76       131\n","\n"]}]},{"cell_type":"code","source":["#\n","# 2. Laser Dataset\n","#\n","print(\"\\nRandom Forest — Laser\")\n","\n","rf_laser = RandomForestClassifier(n_estimators=200, random_state=42)\n","rf_laser.fit(X_laser_train, y_laser_train)\n","\n","y_pred = rf_laser.predict(X_laser_test)\n","\n","acc = accuracy_score(y_laser_test, y_pred)\n","f1  = f1_score(y_laser_test, y_pred, average=\"weighted\")\n","\n","report = classification_report(y_laser_test, y_pred)\n","\n","print(\"\\nRandom Forest — LASER\")\n","print(report)\n","\n","with open(RF_DIR / \"LASER_classification_report.txt\", \"w\") as f:\n","    f.write(report)\n","\n","results.append([\"LASER\", \"Random Forest\", acc, f1])"],"metadata":{"id":"RtxTNxmGCjSR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b6ec7f5-8e91-40a9-d24d-ebcdbc455f48","executionInfo":{"status":"ok","timestamp":1766760018966,"user_tz":0,"elapsed":427,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Random Forest — Laser\n","\n","Random Forest — LASER\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.81      0.84        16\n","           1       0.73      0.80      0.76        10\n","           2       1.00      1.00      1.00        12\n","\n","    accuracy                           0.87        38\n","   macro avg       0.86      0.87      0.87        38\n","weighted avg       0.87      0.87      0.87        38\n","\n"]}]},{"cell_type":"code","source":["#\n","# 3. Combined Dataset\n","#\n","print(\"\\nRandom Forest — Combined\")\n","\n","rf_comb = RandomForestClassifier(n_estimators=200, random_state=42)\n","rf_comb.fit(X_comb_train, y_comb_train)\n","\n","y_pred = rf_comb.predict(X_comb_test)\n","\n","acc = accuracy_score(y_comb_test, y_pred)\n","f1  = f1_score(y_comb_test, y_pred, average=\"weighted\")\n","\n","report = classification_report(y_comb_test, y_pred)\n","\n","print(\"\\nRandom Forest — Combined\")\n","print(report)\n","\n","with open(RF_DIR / \"Combined_classification_report.txt\", \"w\") as f:\n","    f.write(report)\n","\n","results.append([\"Combined\", \"Random Forest\", acc, f1])"],"metadata":{"id":"BlXMTbE5CofC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b68a10c5-4c28-4244-f4ee-e15aadc14ed8","executionInfo":{"status":"ok","timestamp":1766760019374,"user_tz":0,"elapsed":408,"user":{"displayName":"Eden O","userId":"05415712921798345846"}},"collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Random Forest — Combined\n","\n","Random Forest — Combined\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.81      0.87        16\n","           1       0.75      0.90      0.82        10\n","           2       1.00      1.00      1.00        12\n","\n","    accuracy                           0.89        38\n","   macro avg       0.89      0.90      0.89        38\n","weighted avg       0.90      0.89      0.90        38\n","\n"]}]},{"cell_type":"code","source":["#####################################################\n","# Training with Neural Network\n","#####################################################\n","\n","# Setting up the parameters for Neural Network\n","\n","def build_nn(input_dim): #Creates and returns a feed-forward neural network\n","    model = Sequential() #stack layers one after another in a linear order\n","    model.add(Input(shape=(input_dim,))) #takes input_dim numeric features\n","    model.add(Dense(64, activation=\"relu\")) #learn features efficiently\n","    model.add(Dense(32, activation=\"relu\"))\n","    model.add(Dense(3, activation=\"softmax\")) #predicting 3 classes.\n","\n","    model.compile(\n","        optimizer=Adam(learning_rate=0.001), #updates weights during training (Adam is good default choice)\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"] #measures how often the model predicts correctly.\n","    )\n","    return model"],"metadata":{"id":"wos7mn6oQz4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#\n","# 1. Empa Dataset\n","#\n","model = build_nn(X_empa_train.shape[1]) #builds the neural network using the number of input features from the training data.\n","\n","model.fit(\n","    X_empa_train, y_empa_train,\n","    epochs=50, batch_size=32, verbose=0\n",") #epoch goes through training data; training data split into mini batches of 32samples; verbose gives 0 output\n","\n","loss, acc = model.evaluate(X_empa_test, y_empa_test, verbose=0) #evaluates how well the trained model performs on unseen test data.\n","print(\"\\nNeural Network — EMPA\") #loss= The value of the loss function (how wrong the predictions are).\n","print(\"Accuracy:\", acc) #acc= The fraction of correct predictions.\n","\n","y_pred = model.predict(X_empa_test).argmax(axis=1) #multiclass classification\n","\n","acc = accuracy_score(y_empa_test, y_pred)\n","f1  = f1_score(y_empa_test, y_pred, average=\"weighted\")\n","\n","report = classification_report(y_empa_test, y_pred)\n","print(report)\n","\n","with open(NN_DIR / \"EMPA_classification_report.txt\", \"w\") as f:\n","    f.write(report)\n","\n","results.append([\"EMPA\", \"Neural Network\", acc, f1])"],"metadata":{"id":"DbKTpyL5RHHe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"adcb15fc-41fc-4110-e21e-c2449ac09f83","executionInfo":{"status":"ok","timestamp":1766760024992,"user_tz":0,"elapsed":5600,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Neural Network — EMPA\n","Accuracy: 0.8015267252922058\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.79      0.79        53\n","           1       0.76      0.92      0.83        52\n","           2       1.00      0.58      0.73        26\n","\n","    accuracy                           0.80       131\n","   macro avg       0.85      0.76      0.79       131\n","weighted avg       0.82      0.80      0.80       131\n","\n"]}]},{"cell_type":"code","source":["#\n","# 2. Laser Dataset\n","#\n","model = build_nn(X_laser_train.shape[1])\n","\n","model.fit(\n","    X_laser_train, y_laser_train,\n","    epochs=50, batch_size=32, verbose=0\n",")\n","\n","loss, acc = model.evaluate(X_laser_test, y_laser_test, verbose=0)\n","print(\"\\nNeural Network — Laser\")\n","print(\"Accuracy:\", acc)\n","\n","y_pred = model.predict(X_laser_test).argmax(axis=1)\n","\n","acc = accuracy_score(y_laser_test, y_pred)\n","f1  = f1_score(y_laser_test, y_pred, average=\"weighted\")\n","\n","report = classification_report(y_laser_test, y_pred)\n","print(report)\n","\n","with open(NN_DIR / \"Laser_classification_report.txt\", \"w\") as f:\n","    f.write(report)\n","\n","results.append([\"Laser\", \"Neural Network\", acc, f1])"],"metadata":{"id":"RpTZxKz0RObv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aaba69e5-8398-4104-bcb8-50922f8370d1","executionInfo":{"status":"ok","timestamp":1766760035592,"user_tz":0,"elapsed":10599,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Neural Network — Laser\n","Accuracy: 0.8947368264198303\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.81      0.87        16\n","           1       0.75      0.90      0.82        10\n","           2       1.00      1.00      1.00        12\n","\n","    accuracy                           0.89        38\n","   macro avg       0.89      0.90      0.89        38\n","weighted avg       0.90      0.89      0.90        38\n","\n"]}]},{"cell_type":"code","source":["#\n","# 3. Combined\n","#\n","model = build_nn(X_comb_train.shape[1])\n","\n","model.fit(\n","    X_comb_train, y_comb_train,\n","    epochs=50, batch_size=32, verbose=0\n",")\n","\n","loss, acc = model.evaluate(X_comb_test, y_comb_test, verbose=0)\n","print(\"\\nNeural Network — Combined\")\n","print(\"Accuracy:\", acc)\n","\n","y_pred = model.predict(X_comb_test).argmax(axis=1)\n","\n","acc = accuracy_score(y_comb_test, y_pred)\n","f1  = f1_score(y_comb_test, y_pred, average=\"weighted\")\n","\n","report = classification_report(y_comb_test, y_pred)\n","print(report)\n","\n","with open(NN_DIR / \"Combined_classification_report.txt\", \"w\") as f:\n","    f.write(report)\n","\n","results.append([\"Combined\", \"Neural Network\", acc, f1])"],"metadata":{"id":"lIgoflBgRUIr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"40700102-e907-4528-e522-d35d8913aad3","executionInfo":{"status":"ok","timestamp":1766760040964,"user_tz":0,"elapsed":5366,"user":{"displayName":"Eden O","userId":"05415712921798345846"}},"collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d3298a65080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Neural Network — Combined\n","Accuracy: 0.9210526347160339\n","\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d3298a65080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.94      0.91        16\n","           1       0.91      1.00      0.95        10\n","           2       1.00      0.83      0.91        12\n","\n","    accuracy                           0.92        38\n","   macro avg       0.93      0.92      0.92        38\n","weighted avg       0.93      0.92      0.92        38\n","\n"]}]},{"cell_type":"markdown","source":["Saving all the Classification metrics results to a csv file."],"metadata":{"id":"_Weu7FVrZRgf"}},{"cell_type":"code","source":["################################################################\n","# Saving the Consolidated Classification performance metrics to a csv file\n","################################################################\n","\n","results_df = pd.DataFrame(\n","    results,\n","    columns=[\"Dataset\", \"Model\", \"Accuracy\", \"F1_score\"]\n",")\n","\n","results_df.to_csv(RESULTS / \"classification_summary.csv\", index=False)"],"metadata":{"id":"3ZmmStqzTKom"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #########################################################################################################\n","# Part B - Determining which dataset has a greater influence on MG# value using Linear Regression.\n","# - MG# is a mathematically derived value from elements and has an influence\n","#   on the age of volcanic rocks.\n","# - 3 Datasets (similar to the Classification but not identical coz of the different Target)\n","#   have been prepared from 2_DataPreparation:\n","#   - EMPA (653 rows)\n","#   - Laser (189 rows)\n","#   - Combined EMPA + Laser (189 rows)\n","##########################################################################################################"],"metadata":{"id":"JueLH1jYlWQX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["################################################\n","# Training with Linear Regression\n","###############################################\n","\n","#\n","# 1. EMPA Dataset\n","#\n","lr = LinearRegression()\n","lr.fit(X_empa_reg_train, y_empa_reg_train)\n","\n","y_pred = lr.predict(X_empa_reg_test)\n","\n","mse  = mean_squared_error(y_empa_reg_test, y_pred) #Average of squared prediction errors. Penalizes large errors. Lower is better.\n","rmse = np.sqrt(mse) #Square root of MSE. Shows average error in the same units as the target. Lower is better.\n","r2   = r2_score(y_empa_reg_test, y_pred) #Measures how much of the data’s variation the model explains. (1=perfect,0=no better than guessing, negative=very bad)\n","\n","print(\"\\nLinear Regression — EMPA\")\n","print(\"RMSE:\", rmse)\n","print(\"R²:\", r2)\n","\n","reg_results.append([\"EMPA\", rmse, r2])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X3DRNhu7qtuw","outputId":"4240c4ea-ecb0-4208-c4ed-57f7ea8d0427","executionInfo":{"status":"ok","timestamp":1766760041029,"user_tz":0,"elapsed":28,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Linear Regression — EMPA\n","RMSE: 0.006408695957192188\n","R²: 0.9946366544183418\n"]}]},{"cell_type":"code","source":["#\n","# 2. Laser Dataset\n","#\n","lr = LinearRegression()\n","lr.fit(X_laser_reg_train, y_laser_reg_train)\n","\n","y_pred = lr.predict(X_laser_reg_test)\n","\n","mse = mean_squared_error(y_laser_reg_test, y_pred)\n","rmse = np.sqrt(mse)\n","r2   = r2_score(y_laser_reg_test, y_pred)\n","\n","print(\"\\nLinear Regression — LASER\")\n","print(\"RMSE:\", rmse)\n","print(\"R²:\", r2)\n","\n","reg_results.append([\"LASER\", rmse, r2])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWghiwBtrGVe","outputId":"3fbbd122-ada5-4621-ed9d-1e88214f19cb","executionInfo":{"status":"ok","timestamp":1766760041169,"user_tz":0,"elapsed":136,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Linear Regression — LASER\n","RMSE: 0.1678276335271874\n","R²: -1.2856580539871176\n"]}]},{"cell_type":"code","source":["#\n","# 3. Combined Dataset\n","#\n","lr = LinearRegression()\n","lr.fit(X_comb_reg_train, y_comb_reg_train)\n","\n","y_pred = lr.predict(X_comb_reg_test)\n","\n","mse = mean_squared_error(y_comb_reg_test, y_pred)\n","rmse = np.sqrt(mse)\n","r2   = r2_score(y_comb_reg_test, y_pred)\n","\n","print(\"\\nLinear Regression — COMBINED\")\n","print(\"RMSE:\", rmse)\n","print(\"R²:\", r2)\n","\n","reg_results.append([\"COMBINED\", rmse, r2])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-QZV-CfuD7g","outputId":"0505a815-334f-45e1-84f0-8b28b3e4adfa","executionInfo":{"status":"ok","timestamp":1766760041169,"user_tz":0,"elapsed":9,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Linear Regression — COMBINED\n","RMSE: 0.020225884509205774\n","R²: 0.966802959918767\n"]}]},{"cell_type":"code","source":["#############################################################\n","#  Saving the Regression performance metrics to a csv file\n","#############################################################\n","\n","reg_df = pd.DataFrame(\n","    reg_results,\n","    columns=[\"Dataset\", \"RMSE\", \"R2\"]\n",")\n","\n","reg_df.to_csv(REG_DIR / \"linear_regression_summary.csv\", index=False)\n","\n","print(\"Linear regression summary saved.\")\n","\n","###############################################################\n","# End of Stage 2 - Training the Models\n","###############################################################"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DNHCD7NDubjC","outputId":"11a97e8d-610c-4d6f-8864-476bd1ddc295","executionInfo":{"status":"ok","timestamp":1766760041170,"user_tz":0,"elapsed":6,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear regression summary saved.\n"]}]}]}