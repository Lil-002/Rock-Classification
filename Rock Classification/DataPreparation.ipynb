{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KDJpRxrSAedE"},"outputs":[],"source":["##########################################################################\n","# STAGE 1 - DATA PREPARATION\n","# - Data Cleaning of EMPA & Laser Data\n","# - Saving the initial 'clean' data for Data Visualization\n","# - The Data Visualization script is on its own\n","#######################################################################"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import pandas as pd\n","import numpy as np\n","import re # handling regex\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","# import random\n","from pathlib import Path\n","import os\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","\n","# Setting Paths for the files generated\n","ROOT = Path(\"/content/drive/MyDrive/Intro2Prog\")\n","DATA_RAW = ROOT / \"Data_Raw\"\n","DATA_CLEAN = ROOT / \"Data_Clean\"\n","\n","DATA_RAW.mkdir(parents=True, exist_ok=True)\n","DATA_CLEAN.mkdir(parents=True, exist_ok=True)\n","\n","# Load raw data\n","#!ls -al '/content/drive/MyDrive/'"],"metadata":{"id":"Tf6z-UtUBR6j","colab":{"base_uri":"https://localhost:8080/"},"outputId":"138b8a06-d165-4ea8-adc9-0c8416ba74c5","executionInfo":{"status":"ok","timestamp":1766759865759,"user_tz":0,"elapsed":35560,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Load Data file\n","df = pd.read_excel(DATA_RAW / \"Ali New Spreadsheet.xlsx\", sheet_name = 'Ali Spreadsheet')\n","\n","# Inspecting the columen names\n","print('Source File:', df.shape)\n","print('\\nColumns in Source File:')\n","print(df.columns.tolist())"],"metadata":{"id":"XuVGcwwXInVb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"edcc7cab-9e96-4d52-e155-9fe2b9d60f14","executionInfo":{"status":"ok","timestamp":1766759867378,"user_tz":0,"elapsed":1618,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Source File: (653, 58)\n","\n","Columns in Source File:\n","['SAMPLE', 'Lab', 'CaO', 'SiO2', 'Cr2O3', 'Na2O', 'TiO2', 'MnO', 'MgO', 'FeO', 'Al2O3', 'K2O', 'Mg#', 'Li', 'Be', 'B', 'Mg', 'Si', 'Ca', 'Ca.1', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Co', 'Ni', 'Cu', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'Pb', 'Th', 'U', 'C', 'M', 'R', 'T']\n"]}]},{"cell_type":"code","source":["# Noticed duplicated Ca columns in the dataset\n","# perform temporary check - on duplicated columns\n","if 'Ca.1' in df.columns:\n","  print('\\nDuplicated Ca columns found')\n","\n","# Checking on the percentage of missing entries in both columns\n","# to decide on which to keep\n","  ca_missing = df['Ca'].isna().mean()*100\n","  ca1_missing = df['Ca.1'].isna().mean()*100\n","\n","  print(f'Ca missing: {ca_missing:.2f}%')\n","  print(f'Ca.1 missing: {ca1_missing:.2f}%')"],"metadata":{"id":"fT1HIfYsJnTG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0318bfb6-2254-4a6a-e45c-5baf6a748ce8","executionInfo":{"status":"ok","timestamp":1766759867411,"user_tz":0,"elapsed":22,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Duplicated Ca columns found\n","Ca missing: 71.06%\n","Ca.1 missing: 71.06%\n"]}]},{"cell_type":"code","source":["# Both Ca and Ca.1 - has the same no. of missing entries\n","# so keeping the first one - Ca and dropping the second\n","if 'Ca.1' in df.columns:\n","  df = df.drop(columns=['Ca.1'])\n","  print('Ca.1 - Duplicated Ca column is dropped')\n","  print('Source File:', df.shape)\n","  print(df.columns.tolist())"],"metadata":{"id":"MavekGvpKnPf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0301808-76cd-42d3-c659-12a3169b7f9c","executionInfo":{"status":"ok","timestamp":1766759867453,"user_tz":0,"elapsed":31,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ca.1 - Duplicated Ca column is dropped\n","Source File: (653, 57)\n","['SAMPLE', 'Lab', 'CaO', 'SiO2', 'Cr2O3', 'Na2O', 'TiO2', 'MnO', 'MgO', 'FeO', 'Al2O3', 'K2O', 'Mg#', 'Li', 'Be', 'B', 'Mg', 'Si', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Co', 'Ni', 'Cu', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'Pb', 'Th', 'U', 'C', 'M', 'R', 'T']\n"]}]},{"cell_type":"code","source":["# Define the 2 Datasets EMPA and Laser as per the layout in the assignment\n","# For EMPA - there are missing columns - NiO, F, V2O3, ZnO, Li2O\n","# But our focus is on the [Ali Spreadsheet]- the main sheet\n","EMPA_COLS = [\n","    \"CaO\", \"SiO2\", \"Cr2O3\", \"Na2O\", \"TiO2\",\n","    \"MnO\", \"MgO\", \"FeO\", \"Al2O3\", \"K2O\"\n","]\n","\n","LASER_COLS = [\n","    \"Mg#\", \"Li\", \"Be\", \"B\", \"Mg\", \"Si\", \"Ca\", \"Sc\", \"Ti\", \"V\", \"Cr\",\n","    \"Mn\", \"Co\", \"Ni\", \"Cu\", \"Rb\", \"Sr\", \"Y\", \"Zr\", \"Nb\", \"Cs\", \"Ba\", \"La\",\n","    \"Ce\", \"Pr\", \"Nd\", \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\",\n","    \"Lu\", \"Hf\", \"Ta\", \"Pb\", \"Th\", \"U\"\n","]\n","\n","# Performing a Dtype check on them before cleaning\n","print(df[EMPA_COLS].dtypes)\n","print(df[LASER_COLS].dtypes)"],"metadata":{"id":"I5wG0dCcLbwz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b732f924-4ba4-4e5f-dc34-5c0273cb0ac8","executionInfo":{"status":"ok","timestamp":1766759867477,"user_tz":0,"elapsed":17,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CaO      float64\n","SiO2     float64\n","Cr2O3     object\n","Na2O     float64\n","TiO2     float64\n","MnO      float64\n","MgO      float64\n","FeO      float64\n","Al2O3    float64\n","K2O      float64\n","dtype: object\n","Mg#    float64\n","Li      object\n","Be      object\n","B       object\n","Mg     float64\n","Si     float64\n","Ca     float64\n","Sc     float64\n","Ti     float64\n","V      float64\n","Cr      object\n","Mn     float64\n","Co     float64\n","Ni      object\n","Cu      object\n","Rb      object\n","Sr     float64\n","Y      float64\n","Zr     float64\n","Nb     float64\n","Cs      object\n","Ba      object\n","La     float64\n","Ce     float64\n","Pr     float64\n","Nd     float64\n","Sm     float64\n","Eu     float64\n","Gd     float64\n","Tb     float64\n","Dy     float64\n","Ho     float64\n","Er     float64\n","Tm     float64\n","Yb     float64\n","Lu     float64\n","Hf     float64\n","Ta     float64\n","Pb      object\n","Th     float64\n","U      float64\n","dtype: object\n"]}]},{"cell_type":"code","source":["# Examined all columns with dtypes = object and found that there were the following conditions\n","# 'CPX' value in Cr203 column and a lot of '<' types of data in the Laser columns.\n","# Decided to have a simple clean_up value function for doing this\n","# a special handling was needed for the '<' value.\n","# For this - using the best practice in geochemistry - LOD - [Limit of detection divided by 2]\n","def clean_value(x):\n","    if pd.isna(x): #if x is missing, return nan\n","        return np.nan\n","    x = str(x).strip() #converts x to string and removes spaces\n","\n","    # Case 1 : CPX - non numeric - CPX\n","    if x.upper() == 'CPX': #if uppercase and CPX then print\n","        print('CPX')\n","        return np.nan #missing values\n","    # Case 2 : < below a number value\n","    # using regex\n","    # ^ - start of string, < - A literal < char, \\s* - 0 or more spaces after <\n","    # \\d+ - one or more digits (integer),\n","    # (\\.\\d+)? - optional decimal ; \\. literal dot, \\d+ - one or more digits. ? - optional\n","    # $ end of string\n","    if re.match(r\"^<\\s*\\d+(\\.\\d+)?$\", x):\n","        num = float(x.replace('<', '').strip()) #remove < and spaces and change to float\n","        return num/2 # using the LOD/2 method\n","    # normal numeric\n","    try:\n","        return float(x)\n","    except:\n","        return np.nan\n","\n","# applying the above function to both the EMPA and LASER_COLS\n","for col in EMPA_COLS:\n","    df[col] = df[col].apply(clean_value)\n","\n","for col in LASER_COLS:\n","    df[col] = df[col].apply(clean_value)\n","\n","# Quick verification\n","print('Verifying EMPA_COLS - cleanup\\n')\n","print(df[EMPA_COLS].dtypes)\n","print('Verifying LASER_COLS - cleanup\\n')\n","print(df[LASER_COLS].dtypes)\n"],"metadata":{"id":"Ebg9UKAfSjBm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa2bc9c3-9dfc-4ed9-80b9-ff9519f3fbf8","executionInfo":{"status":"ok","timestamp":1766759867579,"user_tz":0,"elapsed":97,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPX\n","Verifying EMPA_COLS - cleanup\n","\n","CaO      float64\n","SiO2     float64\n","Cr2O3    float64\n","Na2O     float64\n","TiO2     float64\n","MnO      float64\n","MgO      float64\n","FeO      float64\n","Al2O3    float64\n","K2O      float64\n","dtype: object\n","Verifying LASER_COLS - cleanup\n","\n","Mg#    float64\n","Li     float64\n","Be     float64\n","B      float64\n","Mg     float64\n","Si     float64\n","Ca     float64\n","Sc     float64\n","Ti     float64\n","V      float64\n","Cr     float64\n","Mn     float64\n","Co     float64\n","Ni     float64\n","Cu     float64\n","Rb     float64\n","Sr     float64\n","Y      float64\n","Zr     float64\n","Nb     float64\n","Cs     float64\n","Ba     float64\n","La     float64\n","Ce     float64\n","Pr     float64\n","Nd     float64\n","Sm     float64\n","Eu     float64\n","Gd     float64\n","Tb     float64\n","Dy     float64\n","Ho     float64\n","Er     float64\n","Tm     float64\n","Yb     float64\n","Lu     float64\n","Hf     float64\n","Ta     float64\n","Pb     float64\n","Th     float64\n","U      float64\n","dtype: object\n"]}]},{"cell_type":"code","source":["# Now that we have cleared the non-numeric issue, we can now check for missingness in the data\n","empa_missing = pd.DataFrame({\n","    \"Missing_Count\": df[EMPA_COLS].isna().sum(),\n","    \"Missing_Percent\": df[EMPA_COLS].isna().mean()*100\n","})\n","\n","laser_missing = pd.DataFrame({\n","    \"Missing_Count\": df[LASER_COLS].isna().sum(),\n","    \"Missing_Percent\": df[LASER_COLS].isna().mean()*100\n","})\n","print('EMPA Missing Values')\n","print(empa_missing)\n","print('LASER Missing Values')\n","print(laser_missing)"],"metadata":{"id":"Vpi0RqWUNgU7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"20225ce3-41e5-4dff-b9fe-42206c592537","executionInfo":{"status":"ok","timestamp":1766759867623,"user_tz":0,"elapsed":43,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["EMPA Missing Values\n","       Missing_Count  Missing_Percent\n","CaO                0         0.000000\n","SiO2               0         0.000000\n","Cr2O3              1         0.153139\n","Na2O               0         0.000000\n","TiO2               0         0.000000\n","MnO                0         0.000000\n","MgO                0         0.000000\n","FeO                0         0.000000\n","Al2O3              0         0.000000\n","K2O                0         0.000000\n","LASER Missing Values\n","     Missing_Count  Missing_Percent\n","Mg#              0         0.000000\n","Li             464        71.056662\n","Be             464        71.056662\n","B              464        71.056662\n","Mg             464        71.056662\n","Si             464        71.056662\n","Ca             464        71.056662\n","Sc             464        71.056662\n","Ti             464        71.056662\n","V              464        71.056662\n","Cr             464        71.056662\n","Mn             464        71.056662\n","Co             464        71.056662\n","Ni             464        71.056662\n","Cu             464        71.056662\n","Rb             464        71.056662\n","Sr             464        71.056662\n","Y              464        71.056662\n","Zr             464        71.056662\n","Nb             464        71.056662\n","Cs             464        71.056662\n","Ba             464        71.056662\n","La             464        71.056662\n","Ce             464        71.056662\n","Pr             464        71.056662\n","Nd             464        71.056662\n","Sm             464        71.056662\n","Eu             464        71.056662\n","Gd             464        71.056662\n","Tb             464        71.056662\n","Dy             464        71.056662\n","Ho             464        71.056662\n","Er             464        71.056662\n","Tm             464        71.056662\n","Yb             464        71.056662\n","Lu             464        71.056662\n","Hf             464        71.056662\n","Ta             464        71.056662\n","Pb             464        71.056662\n","Th             464        71.056662\n","U              464        71.056662\n"]}]},{"cell_type":"code","source":["# This tells us that we have 0.15% missing values in Cr203 column of the EMPA dataset\n","# And many missing values from the Laser Dataset(71%) with the exception of Mg#\n","# Saving this 'clean' data for use in the Data Visualization codes\n","# And for tracability purpose.\n","\n","df.to_csv(DATA_CLEAN / \"df_cleaned.csv\", index=False)"],"metadata":{"id":"dkLLp7yLVbAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##########################################################################\n","# Further Data preparation before its use for modeling\n","# - using the cleaned data to prepare the data for modeling\n","# - Perform the train-test split\n","# - Apply SimpleImputer using Median\n","# - Apply Scaling to normalize the values\n","# - Prepare the Datasets for Modelling\n","#######################################################################\n","\n","# Create the DATA_PREP folder for the output files\n","# This is for trace-ability\n","\n","DATA_PREP  = ROOT / \"Data_Prepared\"\n","DATA_PREP.mkdir(parents=True, exist_ok=True)"],"metadata":{"id":"byxbo0mc49l0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------------------\n","# Create a generic function to prepare data for model training\n","# - For Classification models and Regression models\n","# - Imputer and scaling is done only after train-test split\n","# - to avoid data leakage\n","# - stratify is True for Classification; False for regression\n","# -------------------------------\n","def prepare_features(X, y, stratify=True):\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=42,\n","        stratify=y if stratify else None\n","    ) #stratify=true split data using y to keep class balance; stratify for class balancing\n","\n","    imputer = SimpleImputer(strategy=\"median\") #get the most occuring value incase of outliers which causes mean value to run\n","    X_train = imputer.fit_transform(X_train)\n","    X_test  = imputer.transform(X_test)\n","\n","    scaler = StandardScaler() #makes big and small values on the same scale, to prevent features with large values from dominating smaller ones\n","    X_train = scaler.fit_transform(X_train) #Model learns properly (0 to 1)\n","    X_test  = scaler.transform(X_test) #prevent dataleakage so no fit\n","\n","    return X_train, X_test, y_train.values, y_test.values\n","\n","##################################################################\n","# CREATE 3 Datasets for Classification Models\n","# 1 - EMPA (653 rows)\n","# 2 - Laser (189 rows)\n","# 3 - Combined (EMPA + LASER) - (189 rows)\n","#################################################################\n","\n","#\n","# 1 - Create EMPA - 653 rows\n","#\n","# ['T'] column has to be remaped from [1,2,3] to [0,1,2]\n","# for the Neural Network to work\n","\n","X_empa = df[EMPA_COLS]\n","y_empa = df[\"T\"].map({1:0, 2:1, 3:2}) #sparse_categorical_crossentropy expects class labels as zero-based integers: 0 1 2 not 1 2 3\n","\n","#\n","# 2 - Create Laser data - 189 rows\n","# Decided to drop the 71% missing rows of data\n","# rather than try to create them synthetically\n","# which could lead to severe bias and mislead the model\n","#\n","df_laser = df[LASER_COLS + [\"T\"]].dropna()\n","X_laser = df_laser[LASER_COLS]\n","y_laser = df_laser[\"T\"].map({1:0, 2:1, 3:2})\n","\n","#\n","# 3 - Create Combined Dataset comprising EMPA (189 rows) & Laser (189 rows)\n","#\n","df_comb = df.loc[df_laser.index, EMPA_COLS + LASER_COLS + [\"T\"]] #Create a new DataFrame using selected rows and selected columns.\n","X_comb = df_comb[EMPA_COLS + LASER_COLS]\n","y_comb = df_comb[\"T\"].map({1:0, 2:1, 3:2})\n","\n","#\n","# Generates the 3 sets of Data for training the Classification Models\n","# all imputed & scaled and ready for use in training the Classification Models\n","#\n","# 1st Set - EMPA - 653 rows\n","X_empa_train, X_empa_test, y_empa_train, y_empa_test = prepare_features(X_empa, y_empa)\n","# 2nd Set - Laser - 189 rows\n","X_laser_train, X_laser_test, y_laser_train, y_laser_test = prepare_features(X_laser, y_laser)\n","# 3rd set - Combined - EMPA & Laser - 189 rows\n","X_comb_train, X_comb_test, y_comb_train, y_comb_test = prepare_features(X_comb, y_comb)\n","\n","# Saving the prepared datasets for use in ModelTraining.ipynb script\n","#\n","# 1st Set EMPA (653 rows)\n","np.save(DATA_PREP / \"X_empa_train.npy\", X_empa_train)\n","np.save(DATA_PREP / \"X_empa_test.npy\",  X_empa_test)\n","np.save(DATA_PREP / \"y_empa_train.npy\", y_empa_train)\n","np.save(DATA_PREP / \"y_empa_test.npy\",  y_empa_test)\n","# 2nd set Laser (189 rows)\n","np.save(DATA_PREP / \"X_laser_train.npy\", X_laser_train)\n","np.save(DATA_PREP / \"X_laser_test.npy\",  X_laser_test)\n","np.save(DATA_PREP / \"y_laser_train.npy\", y_laser_train)\n","np.save(DATA_PREP / \"y_laser_test.npy\",  y_laser_test)\n","# 3rd set Combined - EMPA & Laser (189 rows)\n","np.save(DATA_PREP / \"X_comb_train.npy\", X_comb_train)\n","np.save(DATA_PREP / \"X_comb_test.npy\",  X_comb_test)\n","np.save(DATA_PREP / \"y_comb_train.npy\", y_comb_train)\n","np.save(DATA_PREP / \"y_comb_test.npy\",  y_comb_test)\n","\n","print(\"All prepared datasets saved.\")\n","\n","###############################################################\n","# Extension - made for Linear Regression where Target is Mg#\n","# Prepared 3 Datasets\n","# 1 - EMPA (653 rows)\n","# 2 - Laser (189 rows)\n","# 3 - Combined (EMPA & Laser rows)\n","##############################################################\n","\n","#############################################################\n","# 1 - Create EMPA (653 rows) Dataset for Regression\n","#\n","df_empa_full = df[EMPA_COLS + [\"Mg#\"]].copy() #.copy makes a safe copy so changes donâ€™t affect the original DataFrame.\n","\n","X = df_empa_full[EMPA_COLS].copy()\n","y = df_empa_full[\"Mg#\"].copy()\n","\n","# Prepare the sets of EMPA data for the Linear Regression Model\n","# using the same prepare_features function but this round stratify is set to False\n","# All imputed and scaled and ready for use in training the Regression Model\n","#\n","X_empa_reg_train, X_empa_reg_test, y_empa_reg_train, y_empa_reg_test = prepare_features(\n","    X, y, stratify=False\n",") #stratify false because continous value doesn't need balancing\n","\n","# Saving the prepared EMPA datasets for ModelTraining.ipynb script\n","\n","np.save(DATA_PREP / \"X_empa_reg_train.npy\", X_empa_reg_train)\n","np.save(DATA_PREP / \"X_empa_reg_test.npy\", X_empa_reg_test)\n","np.save(DATA_PREP / \"y_empa_reg_train.npy\", y_empa_reg_train)\n","np.save(DATA_PREP / \"y_empa_reg_test.npy\", y_empa_reg_test)\n","\n","print(\"Saved EMPA FULL regression dataset.\")\n","\n","###################################################################\n","# 2 - Create Laser Dataset (189 rows)\n","#\n","# setting laser_features without column Mg#\n","laser_features = [c for c in LASER_COLS if c != \"Mg#\"]\n","\n","# This is to help with column filtering when we want to get Mg# as the Target\n","df_laser_reg = df[laser_features + [\"Mg#\"]].dropna().copy()\n","\n","X = df_laser_reg[laser_features].copy()\n","y = df_laser_reg[\"Mg#\"].copy()\n","\n","# Preparing the sets of laser data for the Linear Regression Model\n","# Using the same prepare_features function with stratify set to False\n","# All imputed and scaled for use in training the Linear Regression Model\n","X_laser_reg_train, X_laser_reg_test, y_laser_reg_train, y_laser_reg_test = prepare_features(\n","    X, y, stratify=False\n",")\n","\n","# Saving the prepared Laser datasets for ModelTraining.ipynb script\n","\n","np.save(DATA_PREP / \"X_laser_reg_train.npy\", X_laser_reg_train)\n","np.save(DATA_PREP / \"X_laser_reg_test.npy\", X_laser_reg_test)\n","np.save(DATA_PREP / \"y_laser_reg_train.npy\", y_laser_reg_train)\n","np.save(DATA_PREP / \"y_laser_reg_test.npy\", y_laser_reg_test)\n","print(\"Saved LASER regression dataset.\")\n","\n","############################################################################\n","# 3- Create the Combined EMPA & Laser Dataset (189 rows)\n","#\n","# Rows where ALL Laser measurements exist\",\n","laser_complete = df[LASER_COLS].notna().all(axis=1)\n","\n","# df.loc uses laser_complete to selects only rows where laser data is available\n","# then selects the required EMPA nad Laser features corresponding to laser_complete rows\n","df_comb_reg = df.loc[laser_complete, EMPA_COLS + laser_features + [\"Mg#\"]].dropna().copy() #Create a new DataFrame using selected rows and selected columns.\n","\n","X = df_comb_reg[EMPA_COLS + laser_features].copy()\n","y = df_comb_reg[\"Mg#\"].copy()\n","\n","#\n","# Prepare the sets of Combined Data for the Linear Regression Model\n","# Using same prepare_features function but with stratify=False for regression\n","# All imputed and scaled for use in training the Linear Regression Model\n","X_comb_reg_train, X_comb_reg_test, y_comb_reg_train, y_comb_reg_test = prepare_features(\n","    X, y, stratify=False\n",")\n","\n","# Saving the prepared Combined datasets for ModelTraining.ipynb script\n","\n","np.save(DATA_PREP / \"X_comb_reg_train.npy\", X_comb_reg_train)\n","np.save(DATA_PREP / \"X_comb_reg_test.npy\", X_comb_reg_test)\n","np.save(DATA_PREP / \"y_comb_reg_train.npy\", y_comb_reg_train)\n","np.save(DATA_PREP / \"y_comb_reg_test.npy\", y_comb_reg_test)\n","\n","print(\"Saved COMBINED regression dataset.\")\n","\n","##################################################################\n","#  END OF STAGE 1 - Data Preparation\n","##################################################################"],"metadata":{"id":"KpoRqfJYUXaJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ad835dbf-6439-462f-d4dc-9cbd0996d32a","executionInfo":{"status":"ok","timestamp":1766759868097,"user_tz":0,"elapsed":354,"user":{"displayName":"Eden O","userId":"05415712921798345846"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All prepared datasets saved.\n","Saved EMPA FULL regression dataset.\n","Saved LASER regression dataset.\n","Saved COMBINED regression dataset.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0M64bxC5LdW6"},"execution_count":null,"outputs":[]}]}